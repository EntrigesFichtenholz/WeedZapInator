üî¥ **Benutzen Sie das Ger√§t verantwortungsvoll! Der Code kann Bugs enthalten, welche unerw√ºnschtes Fehlverhalten hervorrufen k√∂nnen. Genie√üen/Benutzen Sie ihn mit Vorsicht und seien Sie sich sicher, dass Sie die n√∂tigen Schutzma√ünahmen einhalten!** üî¥

Use the device responsibly! The code may contain bugs that can cause undesirable behavior. Use it with caution, and at your own risk!

# WeedZapInator (Zappi) - Autonomes Unkraut-Erkennungs- und Eliminationssystem

## Projekt√ºbersicht
Der WeedZapInator ist ein System, das darauf ausgelegt ist, Unkraut autonom zu erkennen und mit Lasertechnologie zu beseitigen. Das Ziel ist eine umweltfreundliche und effiziente Alternative zu herk√∂mmlichen Unkrautbek√§mpfungsmethoden.

## Ben√∂tigte Python-Bibliotheken

### Hauptbibliotheken
- `numpy`: Numerische Berechnungen und Arrayoperationen
- `opencv-python` (cv2): Bildverarbeitung und Computervision
- `torch`: Deep Learning und neuronale Netze
- `ultralytics`: YOLO-Objekterkennung
- `serial`: Serielle Kommunikation mit dem Laser-Plotter
- `sklearn`: Maschinelles Lernen (Clustering)
- `threading`: Parallele Verarbeitung
- `time`: Zeitmanagement
- `queue`: Threadsichere Warteschlangen
- `statistics`: Statistische Berechnungen
- `mmap`: Speicherabbildung f√ºr Framebuffer
- `json`: Konfigurationsspeicherung
- `dataclasses`: Datenklassen
- `enum`: Aufz√§hlungstypen
- `math`: Mathematische Operationen
  
### Installation
```bash
pip install numpy opencv-python torch ultralytics pyserial scikit-learn
```

## Systemarchitektur
-Sie Ben√∂tigen dringend ein Linux basierendes System wegen dem Frabebuffer! fb0 muss FullHD sein!

-Sie m√ºssen zudem die richtigen Pfade festlegen.. Z.B. f√ºr den ESP32 des Plotters sudo ls /dev/serial/by-id/*
 den ausgegebenen Pfad dann in LaserTx √ºbernehmen

-Achten Sie darauf, dass Sie den richtigen Pad f√ºr die Kammera im detection Script festlegen. Z.B. /dev/video0 oder video1

### Modul√ºbersicht

1. **Detektionsmodul (`JVN_V6detection_module.py`)**
   - Verwendung von YOLOv8 zur Objekterkennung
   - Fortschrittliche Bildverarbeitungstechniken
   - Kamera-Kalibrierung und Verzerrungskorrektur
   - Pr√§zise Positionsberechnung von Objekten
   - Generierung annotierter Frames

2. **Laser-Plotter-Steuerungsmodul (`JVN_V4LaserTx.py`)**
   - Serielle Kommunikation mit dem Laser-Plotter
   - Verwaltung des Maschinenkoordinatensystems
   - Bewegungsanalyse und Positionsverfolgung
   - Bewegungsgrenzen-Schutz
   - Absoluter und relativer Koordinatenmodus

3. **Mustergenerator-Modul (`JVN_V2patternizer.py`)**
   - Generierung verschiedener geometrischer Bewegungsmuster
   - Unterst√ºtzt Kreis-, Spiralen-, Raster- und Zufallsmuster
   - Erstellung von G-Code-Befehlen f√ºr pr√§zise Bewegungen

4. **Hauptausf√ºhrungsmodul (`JVN_V8LaserRunner.py`)**
   - Orchestrierung des gesamten Workflows
   - Threading-Management f√ºr Parallelverarbeitung
   - Implementierung von Objekt-Clustering und Median-Berechnung
   - Koordination der Laser-Plotter-Bewegungen

## Detaillierter Workflow

### Erkennungs- und Zielerfassungsprozess
1. Laser-Plotter initialisieren und Verbindung herstellen
2. Initielles Homing der Maschine durchf√ºhren
3. Videoframes erfassen und Objekterkennung starten
4. Erkannte Objekte verarbeiten:
   - Koordinatenskalierung anwenden
   - Linsenverzerrungen korrigieren
   - √Ñhnliche Erkennungen clustern
   - Medianpositionen berechnen
5. Pr√§zise Bewegungsbefehle berechnen
6. Laser-Plotter zu Unkraut-Positionen dirigieren

## Konfiguration

### Kalibrierung
- `settings.txt`: Skalierungskalibrierung
- Anpassbare Parameter in Detektions- und Plotter-Modulen
- Konfigurations-Optionen f√ºr Mustergenerierung
  (Noch nicht richtig Implementiert bzw. teilweise verbuggt)


  """Das folgende ist ein Audiotranskript, welches ich auch ins Github schreibe:
   
   In diesem Abschnitt erl√§utere ich, wie der Laserplotter zu kalibrieren ist.
   Der Prozess basiert im Wesentlichen auf zwei Skriptdateien, die zum Einsatz kommen: ‚ÄûlaserTX‚Äú in der Version 4 und V6detection
   In der LaserTX Datei finden Sie am unteren Ende Parameter, mit denen Sie den Raum anpassen k√∂nnen, den der Laser nach dem ‚ÄûHoming‚Äú einnimmt. Und die Skalierung der X;Y Achse in der Datei:JVN_V6detection_module.py
   
   Um zu √ºberpr√ºfen, ob alle Einstellungen korrekt sind, k√∂nnen Sie ein kleines Rechteck nahe dem Koordinatenursprung testen. Sobald dies stimmig ist, verschieben Sie bitte Ihre Kalibrierkarte zum an das Ende des Koordinatenursprungs. Nun k√∂nnen Sie den Ma√üstab f√ºr die X- und Y-Achse anpassen.
   
   Dabei ist zu beachten, dass die X-Achse auf dem Bildschirm horizontal und die Y-Achse vertikal verl√§uft, w√§hrend es beim Plotter umgekehrt ist. Das Programm ber√ºcksichtigt dies und tauscht die Achsen entsprechend um.
   
   Der Kalibrierungsvorgang erfordert mehrfaches Wechseln zwischen der Einstellung des Offsets und des Ma√üstabs. Diesen Prozess wiederholen Sie bitte dreimal f√ºr jede Achse, um die Kalibrierung abzuschlie√üen."""

## Hardwareanforderungen
- USB-Verbindung zum Laser-Plotter
- UUSB Kamera
- CUDA-kompatible GPU (empfohlen)

## Sicherheit und Einschr√§nkungen
- Betrieb innerhalb definierter Maschinengrenzen
- Bewegungsvalidierung implementiert
- Erfordert sorgf√§ltige Kalibrierung f√ºr pr√§zise Zielerfassung

## Technische Besonderheiten
- Verwendung von DBSCAN f√ºr Clustering
- Dynamische G-Code-Generierung
- Framebuffer-Rendering
- Serielle Kommunikationsprotokoll-Handling

## Herausforderungen und L√∂sungsans√§tze
- Pr√§zise Koordinatentransformation
- Echtzeitbildverarbeitung
- Robuste Objekterkennung trotz variabler Umgebungsbedingungen

## Zuk√ºnftige Verbesserungen
- Verbesserte Objektklassifizierung
- Dynamische Mustergenerierung
- Erweiterte Clustering-Algorithmen
- Erh√∂hte Maschinenkompatibilit√§t

## Entwickler
Johannes Nitschke - Projektleiter
